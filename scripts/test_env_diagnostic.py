# scripts/test_env_diagnostic.py

"""
Script de diagnostic pour tester l'environnement et identifier les probl√®mes
"""

import os
import sys
import numpy as np

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.environment_configs import PDPEnvironmentConfig
from environments.env_registry import EnvironmentRegistry

def test_basic_functionality():
    """Test des fonctionnalit√©s de base"""
    print("=" * 60)
    print("TEST 1: FONCTIONNALIT√âS DE BASE")
    print("=" * 60)
    
    config = PDPEnvironmentConfig(
        n_products=1,
        horizon=12,
        normalize_observations=False  # D√©sactiv√© pour voir les vraies valeurs
    )
    
    env = EnvironmentRegistry.create('strategic', config)
    
    # Reset
    obs, info = env.reset(seed=42)
    print(f"‚úÖ Reset r√©ussi")
    print(f"   Stock initial: {obs['current_stock']}")
    print(f"   Demandes futures shape: {obs['future_demands'].shape}")
    print(f"   Demande p√©riode 0: {info['demands'][:, 0]}")
    
    # Test d'un step
    action = np.array([0.8, 0.2, 0.1])  # Regular, Overtime, Subcontracting
    obs, reward, terminated, truncated, info = env.step(action)
    
    print(f"\n‚úÖ Step r√©ussi")
    print(f"   Reward: {reward:.2f}")
    print(f"   Stock apr√®s step: {obs['current_stock']}")
    print(f"   Production totale: {info['total_production']:.1f}")
    print(f"   Niveau de service: {info['demand_fulfillment']:.3f}")
    print(f"   Co√ªts: {info['costs']}")
    
    return True

def test_reward_scale():
    """Test de l'√©chelle des rewards"""
    print("\n" + "=" * 60)
    print("TEST 2: √âCHELLE DES REWARDS")
    print("=" * 60)
    
    config = PDPEnvironmentConfig(
        n_products=1,
        horizon=12,
        normalize_observations=False
    )
    
    env = EnvironmentRegistry.create('strategic', config)
    
    # Test avec diff√©rentes actions
    test_actions = [
        ("Faible production", np.array([0.2, 0.0, 0.0])),
        ("Production moyenne", np.array([0.7, 0.1, 0.0])),
        ("Production √©lev√©e", np.array([1.0, 0.5, 0.3])),
        ("Uniquement sous-traitance", np.array([0.0, 0.0, 1.0])),
    ]
    
    rewards = []
    
    for name, action in test_actions:
        env.reset(seed=42)
        obs, reward, _, _, info = env.step(action)
        rewards.append(reward)
        
        print(f"\n{name}:")
        print(f"   Action: R{action[0]:.1f}/O{action[1]:.1f}/S{action[2]:.1f}")
        print(f"   Reward: {reward:.4f}")
        print(f"   Production: {info['total_production']:.1f}")
        print(f"   Stock final: {obs['current_stock'][0]:.1f}")
        print(f"   Service: {info['demand_fulfillment']:.3f}")
    
    print(f"\nüìä Statistiques des rewards:")
    print(f"   Min: {np.min(rewards):.4f}")
    print(f"   Max: {np.max(rewards):.4f}")
    print(f"   Moyenne: {np.mean(rewards):.4f}")
    print(f"   Std: {np.std(rewards):.4f}")
    
    if np.std(rewards) < 0.01:
        print("   ‚ö†Ô∏è  ATTENTION: Les rewards varient tr√®s peu!")
    else:
        print("   ‚úÖ Les rewards ont une variance acceptable")
    
    return True

def test_episode_consistency():
    """Test de coh√©rence sur un √©pisode complet"""
    print("\n" + "=" * 60)
    print("TEST 3: COH√âRENCE D'UN √âPISODE COMPLET")
    print("=" * 60)
    
    config = PDPEnvironmentConfig(
        n_products=1,
        horizon=12,
        normalize_observations=False
    )
    
    env = EnvironmentRegistry.create('strategic', config)
    obs, info = env.reset(seed=42)
    
    total_reward = 0
    stocks = [obs['current_stock'][0]]
    rewards_list = []
    
    print("\nD√©roulement de l'√©pisode (action constante):")
    action = np.array([0.8, 0.1, 0.0])  # Action constante
    
    for period in range(config.horizon):
        obs, reward, terminated, truncated, info = env.step(action)
        total_reward += reward
        stocks.append(obs['current_stock'][0])
        rewards_list.append(reward)
        
        if period < 3 or period >= config.horizon - 2:  # Afficher d√©but et fin
            print(f"   P√©riode {period}: Stock={obs['current_stock'][0]:6.1f}, "
                  f"Reward={reward:7.4f}, Service={info['demand_fulfillment']:.3f}")
    
    print(f"\nüìä R√©sum√© √©pisode:")
    print(f"   Reward total: {total_reward:.2f}")
    print(f"   Reward moyen: {np.mean(rewards_list):.4f}")
    print(f"   Stock min/max: {np.min(stocks):.1f} / {np.max(stocks):.1f}")
    print(f"   Service moyen: {np.mean([info['demand_fulfillment']]):.3f}")
    
    # V√©rifications
    if np.all(np.array(rewards_list) == rewards_list[0]):
        print("   ‚ö†Ô∏è  PROBL√àME: Tous les rewards sont identiques!")
        return False
    else:
        print("   ‚úÖ Les rewards varient pendant l'√©pisode")
        return True

def test_normalization():
    """Test de la normalisation.
    
    NOTE: La normalisation interne (ObservationNormalizer) est desactivee.
    La normalisation est geree par VecNormalize dans le trainer PPO.
    Ce test verifie que les observations brutes sont coherentes.
    """
    print("\n" + "=" * 60)
    print("TEST 4: OBSERVATIONS (VecNormalize gere la normalisation)")
    print("=" * 60)
    
    # L'environnement retourne maintenant des observations brutes
    # VecNormalize dans ppo_trainer.py s'occupe de la normalisation
    config = PDPEnvironmentConfig(
        n_products=1,
        horizon=12,
        normalize_observations=True  # Active VecNormalize dans le trainer
    )
    env = EnvironmentRegistry.create('strategic', config)
    obs, info = env.reset(seed=42)
    
    print("Observations brutes (normalisees par VecNormalize lors de l'entrainement):")
    print(f"   Stock initial: {obs['current_stock']}")
    print(f"   Demandes futures shape: {obs['future_demands'].shape}")
    print(f"   Demandes (min/max): {obs['future_demands'].min():.1f} / "
          f"{obs['future_demands'].max():.1f}")
    
    # Verifications de coherence des observations brutes
    stock = obs['current_stock']
    demands = obs['future_demands']
    
    # Le stock doit etre dans une plage raisonnable
    max_stock = np.array(config.max_stock)
    stock_valid = np.all(stock >= -max_stock) and np.all(stock <= max_stock)
    
    # Les demandes doivent etre positives
    demands_valid = np.all(demands >= 0)
    
    if stock_valid and demands_valid:
        print("   ‚úÖ Observations brutes coherentes")
        print("   ‚ÑπÔ∏è  VecNormalize normalisera ces valeurs pendant l'entrainement")
        return True
    else:
        if not stock_valid:
            print("   ‚ö†Ô∏è  Stock hors limites!")
        if not demands_valid:
            print("   ‚ö†Ô∏è  Demandes negatives detectees!")
        return False

def main():
    """Lance tous les tests"""
    print("\nüîç DIAGNOSTIC DE L'ENVIRONNEMENT PDP\n")
    
    tests = [
        ("Fonctionnalit√©s de base", test_basic_functionality),
        ("√âchelle des rewards", test_reward_scale),
        ("Coh√©rence d'√©pisode", test_episode_consistency),
        ("Normalisation", test_normalization),
    ]
    
    results = []
    for name, test_func in tests:
        try:
            success = test_func()
            results.append((name, success))
        except Exception as e:
            print(f"‚ùå ERREUR dans {name}: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))
    
    # R√©sum√©
    print("\n" + "=" * 60)
    print("R√âSUM√â DES TESTS")
    print("=" * 60)
    
    for name, success in results:
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status}: {name}")
    
    passed = sum(1 for _, s in results if s)
    print(f"\n{passed}/{len(results)} tests r√©ussis")
    
    if passed == len(results):
        print("\nüéâ Tous les tests sont pass√©s! L'environnement est pr√™t.")
    else:
        print("\n‚ö†Ô∏è  Certains tests ont √©chou√©. V√©rifiez les messages ci-dessus.")

if __name__ == "__main__":
    main()
