# √âvaluation

Guide pour √©valuer et comparer les performances des mod√®les.

## üéØ Objectifs de l'√âvaluation

1. **Mesurer les performances** du mod√®le entra√Æn√©
2. **Comparer** avec les strat√©gies baseline
3. **Analyser** les d√©cisions de production
4. **Valider** avant mise en production

## üìä M√©triques d'√âvaluation

### M√©triques Financi√®res

| M√©trique | Description | Formule |
|----------|-------------|---------|
| **Co√ªt Total** | Somme de tous les co√ªts | $\sum C_{prod} + C_{stock} + C_{rupture}$ |
| **Co√ªt Moyen/P√©riode** | Co√ªt par p√©riode | $C_{total} / T$ |
| **Co√ªt de Production** | Co√ªts directs | $\sum c \cdot P$ |
| **Co√ªt de Stockage** | Co√ªts d'inventaire | $\sum h \cdot I$ |
| **Co√ªt de Rupture** | Co√ªts de p√©nurie | $\sum b \cdot B$ |

### M√©triques de Service

| M√©trique | Description | Cible |
|----------|-------------|-------|
| **Service Level** | % demande satisfaite | ‚â• 95% |
| **Fill Rate** | Taux de satisfaction imm√©diate | ‚â• 90% |
| **Stockout Rate** | Fr√©quence des ruptures | ‚â§ 5% |

### M√©triques de Production

| M√©trique | Description |
|----------|-------------|
| **Utilisation Capacit√©** | % capacit√© utilis√©e |
| **Heures Sup. Ratio** | % production en HS |
| **Sous-traitance Ratio** | % production sous-trait√©e |

## üî¨ √âvaluation via Streamlit

### √âtapes

1. Allez dans **üìä √âvaluation**
2. S√©lectionnez le mod√®le √† √©valuer
3. Choisissez les strat√©gies de comparaison
4. D√©finissez le nombre d'√©pisodes (10-50)
5. Lancez l'√©valuation

### R√©sultats Affich√©s

- Tableau comparatif des m√©triques
- Graphiques de performance
- D√©tails par strat√©gie

## üíª √âvaluation via Code

### √âvaluation Simple

```python
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv

from config import get_example_config
from environments import EnvironmentRegistry

def evaluate_model(model_path: str, n_episodes: int = 10):
    """√âvalue un mod√®le PPO"""
    config = get_example_config('rouleurs')
    
    # Recr√©er l'environnement
    def make_env():
        return EnvironmentRegistry.create('strategic', config)
    
    eval_env = DummyVecEnv([make_env])
    
    # Charger VecNormalize si disponible
    vec_norm_path = model_path.replace('model.zip', 'vec_normalize.pkl')
    if os.path.exists(vec_norm_path):
        eval_env = VecNormalize.load(vec_norm_path, eval_env)
        eval_env.training = False
        eval_env.norm_reward = False
    
    # Charger le mod√®le
    model = PPO.load(model_path, env=eval_env)
    
    # √âvaluer
    results = {
        'rewards': [],
        'costs': [],
        'service_levels': [],
        'episode_metrics': []
    }
    
    for episode in range(n_episodes):
        obs = eval_env.reset()
        done = False
        total_reward = 0
        total_cost = 0
        service_levels = []
        metrics = []
        
        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, done, info = eval_env.step(action)
            
            total_reward += reward[0]
            total_cost += sum(info[0]['costs'].values())
            service_levels.append(info[0]['demand_fulfillment'])
            metrics.append(info[0])
        
        results['rewards'].append(total_reward)
        results['costs'].append(total_cost)
        results['service_levels'].append(np.mean(service_levels))
        results['episode_metrics'].append(metrics)
    
    return results
```

### Comparaison avec Baselines

```python
from agents.baseline_strategies import BASELINE_STRATEGIES

def compare_with_baselines(model_path: str, n_episodes: int = 10):
    """Compare le mod√®le PPO avec les baselines"""
    config = get_example_config('rouleurs')
    
    all_results = {}
    
    # √âvaluer PPO
    ppo_results = evaluate_model(model_path, n_episodes)
    all_results['PPO'] = {
        'mean_reward': np.mean(ppo_results['rewards']),
        'std_reward': np.std(ppo_results['rewards']),
        'mean_cost': np.mean(ppo_results['costs']),
        'mean_service': np.mean(ppo_results['service_levels']),
    }
    
    # √âvaluer les baselines
    for name, StrategyClass in BASELINE_STRATEGIES.items():
        rewards = []
        costs = []
        service_levels = []
        
        for _ in range(n_episodes):
            env = EnvironmentRegistry.create('strategic', config)
            strategy = StrategyClass(env)
            reward, info = strategy.run_episode()
            
            total_cost = sum(
                m['costs']['production_cost'] + 
                m['costs']['inventory_cost'] + 
                m['costs']['shortage_cost']
                for m in info['metrics']
            )
            
            rewards.append(reward)
            costs.append(total_cost)
            service_levels.append(
                np.mean([m['demand_fulfillment'] for m in info['metrics']])
            )
        
        all_results[name] = {
            'mean_reward': np.mean(rewards),
            'std_reward': np.std(rewards),
            'mean_cost': np.mean(costs),
            'mean_service': np.mean(service_levels),
        }
    
    return all_results
```

### G√©n√©ration de Rapport

```python
import pandas as pd

def generate_report(results: dict) -> pd.DataFrame:
    """G√©n√®re un rapport comparatif"""
    data = []
    
    for strategy, metrics in results.items():
        data.append({
            'Strat√©gie': strategy,
            'R√©compense Moy.': f"{metrics['mean_reward']:.2f}",
            '√âcart-Type': f"{metrics['std_reward']:.2f}",
            'Co√ªt Total': f"{metrics['mean_cost']:.0f}",
            'Service Level': f"{metrics['mean_service']:.1%}",
        })
    
    df = pd.DataFrame(data)
    df = df.sort_values('R√©compense Moy.', ascending=False)
    
    return df

# Utilisation
results = compare_with_baselines('./models/best_model/model.zip')
report = generate_report(results)
print(report.to_string(index=False))
```

## üìà Analyse D√©taill√©e

### √âvolution Temporelle

```python
import plotly.graph_objects as go

def plot_episode_analysis(metrics: list, title: str = "Analyse d'√âpisode"):
    """Visualise un √©pisode en d√©tail"""
    periods = list(range(1, len(metrics) + 1))
    
    fig = go.Figure()
    
    # Production
    fig.add_trace(go.Bar(
        x=periods,
        y=[m['total_production'] for m in metrics],
        name='Production',
        marker_color='blue'
    ))
    
    # Demande
    fig.add_trace(go.Scatter(
        x=periods,
        y=[m['raw_metrics']['current_demand'][0] for m in metrics],
        mode='lines+markers',
        name='Demande',
        line=dict(color='red', width=2)
    ))
    
    # Stock
    fig.add_trace(go.Scatter(
        x=periods,
        y=[m['inventory_level'][0] for m in metrics],
        mode='lines+markers',
        name='Stock',
        line=dict(color='green', width=2),
        yaxis='y2'
    ))
    
    fig.update_layout(
        title=title,
        xaxis_title='P√©riode',
        yaxis_title='Unit√©s',
        yaxis2=dict(
            title='Stock',
            overlaying='y',
            side='right'
        ),
        legend=dict(x=0.02, y=0.98)
    )
    
    return fig
```

### R√©partition des Co√ªts

```python
def plot_cost_breakdown(metrics: list):
    """Visualise la r√©partition des co√ªts"""
    costs = {
        'Production': sum(m['costs']['production_cost'] for m in metrics),
        'Stockage': sum(m['costs']['inventory_cost'] for m in metrics),
        'Rupture': sum(m['costs']['shortage_cost'] for m in metrics),
    }
    
    fig = go.Figure(data=[go.Pie(
        labels=list(costs.keys()),
        values=list(costs.values()),
        hole=0.4
    )])
    
    fig.update_layout(title='R√©partition des Co√ªts')
    
    return fig
```

## ‚úÖ Crit√®res de Validation

### Avant Mise en Production

| Crit√®re | Seuil | Validation |
|---------|-------|------------|
| Service Level | ‚â• 95% | ‚úÖ Obligatoire |
| Co√ªt vs L4L | ‚â§ 100% | ‚úÖ Recommand√© |
| Stabilit√© (std) | < 10% | ‚úÖ Recommand√© |
| Consistance | 10+ √©pisodes | ‚úÖ Obligatoire |

### Checklist

- [ ] √âvaluation sur 50+ √©pisodes
- [ ] Comparaison avec toutes les baselines
- [ ] Service level ‚â• 95%
- [ ] Co√ªt total ‚â§ meilleure baseline
- [ ] Analyse des cas extr√™mes
- [ ] Test avec demande "extreme"

## Prochaine √âtape

‚û°Ô∏è [Strat√©gies Baseline](baselines.md)
